{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from matplotlib import pyplot as plt\n",
    "import yaml\n",
    "import pickle\n",
    "# Gaoyj1019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('testdata.txt') as f:\n",
    "    sentences = f.readlines()\n",
    "# print(sentences)\n",
    "MAX_SENT_LEN = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input_vocab\", \"rb\") as fp:   # Unpickling\n",
    "    eng_sentences = pickle.load(fp)\n",
    "with open(\"target_vocab\", \"rb\") as fp:   # Unpickling\n",
    "    deu_sentences = pickle.load(fp)\n",
    "    \n",
    "# eng_words.update(eng_sent)\n",
    "  # deu_words.update(deu_sent)\n",
    "with open(\"input_words\", \"rb\") as fp:   # Unpickling\n",
    "    eng_words = pickle.load(fp)\n",
    "with open(\"target_words\", \"rb\") as fp:   # Unpickling\n",
    "    deu_words = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENG_VOCAB_SIZE = len(eng_words)\n",
    "DEU_VOCAB_SIZE = len(deu_words)\n",
    "NUM_EPOCHS = 20\n",
    "HIDDEN_SIZE = 16\n",
    "EMBEDDING_DIM = 30\n",
    "BATCH_SIZE = 128\n",
    "NUM_HEADS = 2\n",
    "NUM_LAYERS = 3\n",
    "LEARNING_RATE = 1e-3\n",
    "DROPOUT = .3\n",
    "DEVICE = torch.device('cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6956 4599 30 16 2 3 10 10 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/postgrads/2650807G/spack/opt/spack/linux-centos7-x86_64_v3/gcc-4.8.5/anaconda3-2022.10-ldbv2ghkumdvkfs6y6xxwrtticnzqxhf/envs/BioTokens-cpu/lib/python3.11/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransformerNet(\n",
       "  (enc_embedding): Embedding(6956, 30)\n",
       "  (dec_embedding): Embedding(4599, 30)\n",
       "  (enc_pe): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (dec_pe): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=30, out_features=30, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=30, out_features=16, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=16, out_features=30, bias=True)\n",
       "        (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=30, out_features=30, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=30, out_features=30, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=30, out_features=16, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=16, out_features=30, bias=True)\n",
       "        (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((30,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "        (dropout3): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense): Linear(in_features=30, out_features=4599, bias=True)\n",
       "  (log_softmax): LogSoftmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ENG_VOCAB_SIZE, DEU_VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_SIZE, NUM_HEADS, NUM_LAYERS, MAX_SENT_LEN, MAX_SENT_LEN, DROPOUT)\n",
    "\n",
    "model = TransformerNet(ENG_VOCAB_SIZE, DEU_VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_SIZE, NUM_HEADS, NUM_LAYERS, MAX_SENT_LEN, MAX_SENT_LEN, DROPOUT).to(DEVICE)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "model.load_state_dict(torch.load('mymodel.mp'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4280, 1939,  428, 1925, 3598, 3078, 4588, 2170, 2170, 3071]])\n",
      "tensor([[4280, 2637, 2585, 1271, 3973, 2460, 4222, 2047, 2611, 4588]],\n",
      "       dtype=torch.int32)\n",
      "['<sos>', 'wenn', 'du', 'so', 'm√ºde', 'bist', 'geh', 'ins', 'bett', '<eos>']\n",
      "['<sos>', 'i', 'm', 'very', 'angry', 'now', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "['<sos>', 'i', 'm', 'very', 'with', 'now', '<eos>', '<pad>', '<pad>', 'trout']\n"
     ]
    }
   ],
   "source": [
    "outputs = model(torch.tensor(eng_sentences[4],dtype=torch.int).reshape(1,-1),torch.tensor(deu_sentences[3],dtype=torch.int).reshape(1,-1))\n",
    "_, y_pred = torch.max(outputs.permute(1,2,0).data, 1)\n",
    "\n",
    "print(y_pred)\n",
    "print(torch.tensor(deu_sentences[4],dtype=torch.int).reshape(1,-1))\n",
    "\n",
    "input_x =  [eng_words[k] for k in torch.tensor(eng_sentences[4],dtype=torch.int).reshape(1,-1)[0]]\n",
    "target_y = [deu_words[k] for k in torch.tensor(deu_sentences[3],dtype=torch.int).reshape(1,-1)[0]]\n",
    "output_y = [deu_words[k] for k in y_pred[0]]\n",
    "print(input_x)\n",
    "print(target_y)\n",
    "print(output_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioTokens-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
