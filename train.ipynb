{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from matplotlib import pyplot as plt\n",
    "import yaml\n",
    "import pickle\n",
    "# Gaoyj1019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('deu.txt') as f:\n",
    "    sentences = f.readlines()\n",
    "# print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 54135.28it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 36042.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[353, 306, 278, 119, 273, 310, 196, 196, 196, 196]\n",
      "['<sos>', '824', '0', '767', '862', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "[9, 15, 15, 2, 18, 18, 18, 18, 18, 18]\n",
      "['<sos>', 'c', 'c', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_INSTANCES = 10000\n",
    "MAX_SENT_LEN = 10\n",
    "eng_sentences, deu_sentences = [], []\n",
    "eng_words, deu_words = set(), set()\n",
    "for i in tqdm(range(NUM_INSTANCES)):\n",
    "  rand_idx = np.random.randint(len(sentences))\n",
    "  # find only letters in sentences\n",
    "  eng_sent, deu_sent = [\"<sos>\"], [\"<sos>\"]\n",
    "\n",
    "  eng_sent += re.findall(r\"\\w+\", sentences[rand_idx].split(\"\\t\")[1]) \n",
    "  deu_sent += re.findall(r\"\\w+\", sentences[rand_idx].split(\"\\t\")[0])\n",
    "\n",
    "  # change to lowercase\n",
    "  eng_sent = [x.lower() for x in eng_sent]\n",
    "  deu_sent = [x.lower() for x in deu_sent]\n",
    "  eng_sent.append(\"<eos>\")\n",
    "  deu_sent.append(\"<eos>\")\n",
    "\n",
    "  if len(eng_sent) >= MAX_SENT_LEN:\n",
    "    eng_sent = eng_sent[:MAX_SENT_LEN]\n",
    "  else:\n",
    "    for _ in range(MAX_SENT_LEN - len(eng_sent)):\n",
    "      eng_sent.append(\"<pad>\")\n",
    "\n",
    "  if len(deu_sent) >= MAX_SENT_LEN:\n",
    "    deu_sent = deu_sent[:MAX_SENT_LEN]\n",
    "  else:\n",
    "    for _ in range(MAX_SENT_LEN - len(deu_sent)):\n",
    "      deu_sent.append(\"<pad>\")\n",
    "\n",
    "  # add parsed sentences\n",
    "  eng_sentences.append(eng_sent)\n",
    "  deu_sentences.append(deu_sent)\n",
    "\n",
    "  # update unique words\n",
    "  eng_words.update(eng_sent)\n",
    "  deu_words.update(deu_sent)\n",
    "\n",
    "eng_words, deu_words = list(eng_words), list(deu_words)\n",
    "\n",
    "# encode each token into index\n",
    "for i in tqdm(range(len(eng_sentences))):\n",
    "  eng_sentences[i] = [eng_words.index(x) for x in eng_sentences[i]]\n",
    "  deu_sentences[i] = [deu_words.index(x) for x in deu_sentences[i]]\n",
    "\n",
    "idx = 10\n",
    "print(eng_sentences[idx])\n",
    "print([eng_words[x] for x in eng_sentences[idx]])\n",
    "print(deu_sentences[idx])\n",
    "print([deu_words[x] for x in deu_sentences[idx]])\n",
    "\n",
    "with open(\"input_vocab\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(eng_sentences, fp)\n",
    "with open(\"target_vocab\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(deu_sentences, fp)\n",
    "with open(\"input_words\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(eng_words, fp)\n",
    "with open(\"target_words\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(deu_words, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENG_VOCAB_SIZE = len(eng_words)\n",
    "DEU_VOCAB_SIZE = len(deu_words)\n",
    "NUM_EPOCHS = 20\n",
    "HIDDEN_SIZE = 16\n",
    "EMBEDDING_DIM = 30\n",
    "BATCH_SIZE = 128\n",
    "NUM_HEADS = 2\n",
    "NUM_LAYERS = 3\n",
    "LEARNING_RATE = 1e-3\n",
    "DROPOUT = .3\n",
    "DEVICE = torch.device('cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(777)   # for reproducibility\n",
    "dataset = MTDataset(eng_sentences, deu_sentences)\n",
    "NUM_INSTANCES = len(dataset)\n",
    "TEST_RATIO = 0.3\n",
    "TEST_SIZE = int(NUM_INSTANCES * 0.3)\n",
    "\n",
    "indices = list(range(NUM_INSTANCES))\n",
    "\n",
    "test_idx = np.random.choice(indices, size = TEST_SIZE, replace = False)\n",
    "train_idx = list(set(indices) - set(test_idx))\n",
    "train_sampler, test_sampler = SubsetRandomSampler(train_idx), SubsetRandomSampler(test_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size = BATCH_SIZE, sampler = train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size = BATCH_SIZE, sampler = test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/postgrads/2650807G/spack/opt/spack/linux-centos7-x86_64_v3/gcc-4.8.5/anaconda3-2022.10-ldbv2ghkumdvkfs6y6xxwrtticnzqxhf/envs/BioTokens-cpu/lib/python3.11/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "475 25 30 16 2 3 10 10 0.3\n"
     ]
    }
   ],
   "source": [
    "model = TransformerNet(ENG_VOCAB_SIZE, DEU_VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_SIZE, NUM_HEADS, NUM_LAYERS, MAX_SENT_LEN, MAX_SENT_LEN, DROPOUT).to(DEVICE)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "\n",
    "print(ENG_VOCAB_SIZE, DEU_VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_SIZE, NUM_HEADS, NUM_LAYERS, MAX_SENT_LEN, MAX_SENT_LEN, DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[353, 214, 278,  ..., 196, 196, 196],\n",
      "        [353, 303, 278,  ..., 196, 196, 196],\n",
      "        [353, 276, 278,  ..., 196, 196, 196],\n",
      "        ...,\n",
      "        [353, 390, 361,  ..., 310, 196, 196],\n",
      "        [353,   0, 278,  ..., 196, 196, 196],\n",
      "        [353, 289, 278,  ..., 196, 196, 196]]) tensor([[ 9,  6, 14,  ..., 18, 18, 18],\n",
      "        [ 9,  6,  5,  ..., 18, 18, 18],\n",
      "        [ 9, 19, 12,  ..., 18, 18, 18],\n",
      "        ...,\n",
      "        [ 9,  8, 15,  ..., 18, 18, 18],\n",
      "        [ 9, 17,  5,  ..., 18, 18, 18],\n",
      "        [ 9, 14, 19,  ..., 18, 18, 18]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/postgrads/2650807G/spack/opt/spack/linux-centos7-x86_64_v3/gcc-4.8.5/anaconda3-2022.10-ldbv2ghkumdvkfs6y6xxwrtticnzqxhf/envs/BioTokens-cpu/lib/python3.11/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[353,  18, 278,  ..., 196, 196, 196],\n",
      "        [353, 214, 278,  ..., 196, 196, 196],\n",
      "        [353, 289, 278,  ..., 196, 196, 196],\n",
      "        ...,\n",
      "        [353, 403, 278,  ..., 196, 196, 196],\n",
      "        [353, 391, 442,  ..., 310, 196, 196],\n",
      "        [353, 337, 278,  ..., 196, 196, 196]]) tensor([[ 9, 12, 16,  ..., 18, 18, 18],\n",
      "        [ 9,  3, 23,  ..., 18, 18, 18],\n",
      "        [ 9, 23, 19,  ..., 18, 18, 18],\n",
      "        ...,\n",
      "        [ 9,  0, 13,  ..., 18, 18, 18],\n",
      "        [ 9, 11, 15,  ..., 18, 18, 18],\n",
      "        [ 9, 21, 16,  ..., 18, 18, 18]])\n",
      "tensor([[353, 399, 278,  ..., 196, 196, 196],\n",
      "        [353,  99, 436,  ..., 196, 196, 196],\n",
      "        [353,  59, 278,  ..., 196, 196, 196],\n",
      "        ...,\n",
      "        [353, 469, 278,  ..., 196, 196, 196],\n",
      "        [353,  18, 278,  ..., 196, 196, 196],\n",
      "        [353, 274, 278,  ..., 196, 196, 196]]) tensor([[ 9,  7, 17,  ..., 18, 18, 18],\n",
      "        [ 9, 14, 22,  ..., 18, 18, 18],\n",
      "        [ 9,  0,  0,  ..., 18, 18, 18],\n",
      "        ...,\n",
      "        [ 9, 16, 23,  ..., 18, 18, 18],\n",
      "        [ 9,  3, 19,  ..., 18, 18, 18],\n",
      "        [ 9, 16, 23,  ..., 18, 18, 18]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:15<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:7\u001b[0m\n",
      "File \u001b[0;32m~/spack/opt/spack/linux-centos7-x86_64_v3/gcc-4.8.5/anaconda3-2022.10-ldbv2ghkumdvkfs6y6xxwrtticnzqxhf/envs/BioTokens-cpu/lib/python3.11/site-packages/ipykernel/kernelbase.py:1251\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1249\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1250\u001b[0m     \u001b[39mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1251\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_input_request(\n\u001b[1;32m   1252\u001b[0m     \u001b[39mstr\u001b[39;49m(prompt),\n\u001b[1;32m   1253\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent_ident[\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   1254\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_parent(\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1255\u001b[0m     password\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1256\u001b[0m )\n",
      "File \u001b[0;32m~/spack/opt/spack/linux-centos7-x86_64_v3/gcc-4.8.5/anaconda3-2022.10-ldbv2ghkumdvkfs6y6xxwrtticnzqxhf/envs/BioTokens-cpu/lib/python3.11/site-packages/ipykernel/kernelbase.py:1295\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1292\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[39m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mInterrupted by user\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1295\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1297\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mInvalid Message:\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loss_trace = []\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "  current_loss = 0\n",
    "  for i, (x, y) in enumerate(train_loader):\n",
    "    x, y  = x.to(DEVICE), y.to(DEVICE)\n",
    "    print(x,y)\n",
    "    outputs = model(x, y)\n",
    "    loss = criterion(outputs.permute(1, 2, 0), y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    current_loss += loss.item()\n",
    "  loss_trace.append(current_loss)\n",
    "torch.save(model.state_dict(), 'mymodel.mp')\n",
    "\n",
    "# loss curve\n",
    "plt.plot(range(1, NUM_EPOCHS+1), loss_trace, 'r-')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioTokens-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
